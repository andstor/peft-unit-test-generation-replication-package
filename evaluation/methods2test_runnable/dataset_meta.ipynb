{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods2Test Meta Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Golden Commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628010ec51334ff9ac26ff214750ce0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5f44fbe6cc4e18942ddac4a532c483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import DatasetDict, Features, Sequence, Value\n",
    "\n",
    "ddict = DatasetDict()\n",
    "from datasets import DatasetDict, Features, Sequence, Value\n",
    "\n",
    "feat = Features(\n",
    "    {\n",
    "        \"id\": Value(dtype=\"string\"),\n",
    "        \"commit\": Value(dtype=\"string\"),\n",
    "        \"candidates\": Value(dtype=\"string\"),\n",
    "    }\n",
    ")\n",
    "\n",
    "for split in [\"validation\", \"test\"]:\n",
    "    def gen_ds():\n",
    "        with open(f\".data/commits_{split}.jsonl\") as f:\n",
    "            for line in f:\n",
    "                yield json.loads(line)\n",
    "            \n",
    "    ds = Dataset.from_generator(generator=gen_ds, features=feat)\n",
    "    ddict[split] = ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ddict.push_to_hub(\"andstor/methods2test_meta\", config_name=\"commit_candidates\", private=False, max_shard_size=\"250MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddict = ddict.remove_columns(column_names=[\"candidates\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ddict.push_to_hub(\"andstor/methods2test_meta\", config_name=\"golden_commit\", private=False, max_shard_size=\"250MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Statuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_meta = load_dataset(\"andstor/methods2test_meta\", \"golden_commit\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6016a11f26c848d6b454ed96645f9c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import DatasetDict, Features, Sequence, Value\n",
    "\n",
    "\n",
    "feat = Features(\n",
    "    {\n",
    "    'id': Value(dtype='string', id=None),\n",
    "    'build_tool': Value(dtype='string', id=None),\n",
    "    'status': Value(dtype='string', id=None)\n",
    "    }\n",
    ")\n",
    "\n",
    "runnable_data = []\n",
    "with open(f\"./output/runnable.jsonl\") as f:\n",
    "    for line in f:\n",
    "        runnable_data.append(json.loads(line))\n",
    "            \n",
    "runnable_df = pd.DataFrame(runnable_data).set_index(\"id\")\n",
    "runnable_df[\"repo_id\"] = runnable_df.index.str.split(\"_\").str[0]\n",
    "runnable_df[\"test_id\"] = runnable_df.index.str.split(\"_\").str[1]\n",
    "runnable_df = runnable_df.reset_index().set_index(\"repo_id\")\n",
    "\n",
    "def gen_ds():\n",
    "    for row in dataset_meta:\n",
    "        repo_id = row[\"id\"].split(\"_\")[0]\n",
    "    \n",
    "        if repo_id in runnable_df.index:\n",
    "            runnable_row = runnable_df.loc[repo_id]\n",
    "            row[\"build_tool\"] = runnable_row[\"build_tool\"]\n",
    "            row[\"status\"] = runnable_row[\"status\"]\n",
    "            yield row\n",
    "        \n",
    "        else:\n",
    "            yield row\n",
    "\n",
    "ds = Dataset.from_generator(generator=gen_ds, features=feat, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "build error    34953\n",
       "success         7141\n",
       "error            255\n",
       "skipped            6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.to_pandas()[\"status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a365dec365f14bbcb1c74b96c82dbf2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e0290aa55d483da169f16342ab1e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787f6ba556104b6fbb1a6b0339c6879c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/andstor/methods2test_meta/commit/e57ba2b686510d2c857936c97d32c3f3a32a81b3', commit_message='Upload dataset', commit_description='', oid='e57ba2b686510d2c857936c97d32c3f3a32a81b3', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/andstor/methods2test_meta', endpoint='https://huggingface.co', repo_type='dataset', repo_id='andstor/methods2test_meta'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ds.push_to_hub(\"andstor/methods2test_meta\", config_name=\"test_status\", private=False, max_shard_size=\"250MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
